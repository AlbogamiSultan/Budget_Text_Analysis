{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>word</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>537</td>\n",
       "      <td>Fire</td>\n",
       "      <td>46</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>414</td>\n",
       "      <td>Fire</td>\n",
       "      <td>44</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415</td>\n",
       "      <td>Fire</td>\n",
       "      <td>36</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>534</td>\n",
       "      <td>Fire</td>\n",
       "      <td>31</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>531</td>\n",
       "      <td>Fire</td>\n",
       "      <td>29</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  word  sent_count sentiment category\n",
       "0          537  Fire          46      Fear  Emotion\n",
       "1          414  Fire          44      Fear  Emotion\n",
       "2          415  Fire          36      Fear  Emotion\n",
       "3          534  Fire          31      Fear  Emotion\n",
       "4          531  Fire          29      Fear  Emotion"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC_df_2 = pd.read_csv(r\"../util/data/FY2018/structured/emotion/GuilfordCountyEmotionDataFY18.csv\")\n",
    "GC_df_2.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
    "GC_df_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m spacy download en\n",
    "import re, numpy as np, pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>word</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447</td>\n",
       "      <td>Fire</td>\n",
       "      <td>46</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>Fire</td>\n",
       "      <td>44</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>Fire</td>\n",
       "      <td>36</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>444</td>\n",
       "      <td>Fire</td>\n",
       "      <td>31</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>389</td>\n",
       "      <td>County</td>\n",
       "      <td>30</td>\n",
       "      <td>Trust</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number    word  sent_count sentiment category\n",
       "0          447    Fire          46      Fear  Emotion\n",
       "1          302    Fire          44      Fear  Emotion\n",
       "2          303    Fire          36      Fear  Emotion\n",
       "3          444    Fire          31      Fear  Emotion\n",
       "4          389  County          30     Trust  Emotion"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC_df = pd.read_csv(r\"../util/data/FY2019/structured/emotion/GuilfordCountyEmotionDataFY19.csv\")\n",
    "GC_df.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
    "GC_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fire']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent)  \n",
    "\n",
    "# Convert to list\n",
    "data = GC_df_2.word.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])\n",
    "# [['from', 'irwin', 'arnstein', 'subject', 're', 'recommendation', 'on', 'duc', 'summary', 'whats', 'it', 'worth', 'distribution', 'usa', 'expires', 'sat', 'may', 'gmt', ...trucated...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# !python3 -m spacy download en  # run in terminal once\n",
    "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.185*\"grant\" + 0.166*\"level\" + 0.106*\"child\" + 0.094*\"balance\" + '\n",
      "  '0.088*\"food\" + 0.057*\"expense\" + 0.053*\"technology\" + 0.051*\"detention\" + '\n",
      "  '0.039*\"demand\" + 0.033*\"long\"'),\n",
      " (1,\n",
      "  '0.320*\"improve\" + 0.305*\"budget\" + 0.102*\"develop\" + 0.051*\"authorize\" + '\n",
      "  '0.036*\"personal\" + 0.030*\"full\" + 0.015*\"recovery\" + 0.012*\"disposal\" + '\n",
      "  '0.011*\"innovation\" + 0.010*\"vision\"'),\n",
      " (2,\n",
      "  '0.369*\"resource\" + 0.216*\"continue\" + 0.128*\"salary\" + 0.051*\"loss\" + '\n",
      "  '0.030*\"expenditure\" + 0.027*\"population\" + 0.027*\"prevention\" + '\n",
      "  '0.022*\"violence\" + 0.010*\"illegal\" + 0.006*\"machine\"'),\n",
      " (3,\n",
      "  '0.202*\"medical\" + 0.145*\"income\" + 0.091*\"present\" + 0.080*\"improvement\" + '\n",
      "  '0.072*\"legal\" + 0.068*\"soil\" + 0.046*\"account\" + 0.040*\"communication\" + '\n",
      "  '0.038*\"approval\" + 0.026*\"stone\"'),\n",
      " (4,\n",
      "  '0.140*\"management\" + 0.126*\"actual\" + 0.125*\"government\" + 0.122*\"change\" + '\n",
      "  '0.083*\"building\" + 0.079*\"risk\" + 0.066*\"time\" + 0.052*\"call\" + '\n",
      "  '0.039*\"operation\" + 0.028*\"serve\"'),\n",
      " (5,\n",
      "  '0.163*\"fee\" + 0.102*\"community\" + 0.101*\"director\" + 0.092*\"law\" + '\n",
      "  '0.078*\"court\" + 0.073*\"enforcement\" + 0.063*\"conservation\" + 0.051*\"youth\" '\n",
      "  '+ 0.041*\"reimbursement\" + 0.028*\"healthy\"'),\n",
      " (6,\n",
      "  '0.310*\"emergency\" + 0.125*\"school\" + 0.098*\"debt\" + 0.092*\"attorney\" + '\n",
      "  '0.083*\"exceed\" + 0.071*\"real\" + 0.035*\"base\" + 0.035*\"bond\" + '\n",
      "  '0.031*\"appropriation\" + 0.012*\"nurse\"'),\n",
      " (7,\n",
      "  '0.093*\"public\" + 0.087*\"include\" + 0.064*\"high\" + 0.039*\"retirement\" + '\n",
      "  '0.034*\"renovation\" + 0.034*\"effective\" + 0.033*\"progress\" + 0.032*\"share\" + '\n",
      "  '0.030*\"efficient\" + 0.027*\"abuse\"'),\n",
      " (8,\n",
      "  '0.252*\"provide\" + 0.152*\"information\" + 0.099*\"cash\" + 0.093*\"pay\" + '\n",
      "  '0.060*\"supply\" + 0.051*\"recreation\" + 0.041*\"relate\" + 0.040*\"fire\" + '\n",
      "  '0.039*\"jail\" + 0.024*\"rescue\"'),\n",
      " (9,\n",
      "  '0.279*\"planning\" + 0.184*\"tax\" + 0.108*\"increase\" + 0.100*\"system\" + '\n",
      "  '0.081*\"maintenance\" + 0.059*\"disaster\" + 0.033*\"interest\" + '\n",
      "  '0.025*\"customer\" + 0.020*\"late\" + 0.016*\"culture\"')]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           passes=10,\n",
    "                                           alpha = 'auto',\n",
    "                                           eta = 'auto',\n",
    "                                           random_state = 1)\n",
    "\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Corpus for test data: Term Document Frequency\n",
    "test_corpus = [id2word.doc2bow(text) for text in data_ready]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vecs = []\n",
    "for i in range(len(GC_df_2)):\n",
    "    top_topics = lda_model.get_document_topics(test_corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(10)]\n",
    "    topic_vec.extend([len(GC_df_2.iloc[i].word)]) # length review\n",
    "    test_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19475"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19475"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(GC_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_df_2.sentiment = GC_df_2.sentiment.replace({\"Negative\": \"0\",\"Positive\": \"1\",\"Trust\" :\"1\",\"Sadness\":\"0\",\"Anticipation\":\"1\",\"Surprise\":\"1\",\"Fear\":\"0\",\"Joy\":\"1\",\"Anger\":\"0\",\"Disgust\":\"0\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>word</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>537</td>\n",
       "      <td>Fire</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>414</td>\n",
       "      <td>Fire</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415</td>\n",
       "      <td>Fire</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>534</td>\n",
       "      <td>Fire</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>531</td>\n",
       "      <td>Fire</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  word  sent_count sentiment category\n",
       "0          537  Fire          46         0  Emotion\n",
       "1          414  Fire          44         0  Emotion\n",
       "2          415  Fire          36         0  Emotion\n",
       "3          534  Fire          31         0  Emotion\n",
       "4          531  Fire          29         0  Emotion"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19475 entries, 0 to 19474\n",
      "Data columns (total 5 columns):\n",
      "page_number    19475 non-null int64\n",
      "word           19475 non-null object\n",
      "sent_count     19475 non-null int64\n",
      "sentiment      19475 non-null int64\n",
      "category       19475 non-null object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 760.8+ KB\n"
     ]
    }
   ],
   "source": [
    "GC_df_2['sentiment'] = pd.to_numeric(GC_df_2['sentiment'])\n",
    "GC_df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(test_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(GC_df_2.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8775611031997443\n",
      "0.883026010151702\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(X)\n",
    "\n",
    "lr = LogisticRegression(\n",
    "  class_weight= None,\n",
    "  solver='newton-cg',\n",
    "  fit_intercept=True\n",
    "  ).fit(X, y)\n",
    "\n",
    "y_pred_lr = lr.predict(X)\n",
    "print(f1_score(y, y_pred_lr,average='binary'))\n",
    "\n",
    "sgd_huber = linear_model.SGDClassifier(\n",
    "       max_iter=100,\n",
    "        tol=1e-3,\n",
    "        alpha=20,\n",
    "        loss='modified_huber',\n",
    "        class_weight= None\n",
    "    ).fit(X, y)\n",
    "    \n",
    "y_pred_huber = sgd_huber.predict(X)\n",
    "print(f1_score(y, y_pred_huber, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
