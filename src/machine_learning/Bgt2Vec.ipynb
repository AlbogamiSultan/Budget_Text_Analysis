{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bgt2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code is generated from © Yuriy Guts, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim.models.word2vec as w2v\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Download NLTK tokenizer models (only the first time)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sultan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the current directory to read the data\n",
    "os.chdir(r\"C:\\Users\\Sultan\\Desktop\\data\\PreprocessedData\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CombinedData.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿word</th>\n",
       "      <th>organization</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fiscal</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>year</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>adopted</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>budget</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>brenda</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ï»¿word     organization    year\n",
       "0   fiscal  Guilford County  FY2013\n",
       "1     year  Guilford County  FY2013\n",
       "2  adopted  Guilford County  FY2013\n",
       "3   budget  Guilford County  FY2013\n",
       "4   brenda  Guilford County  FY2013"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>organization</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fiscal</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>year</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>adopted</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>budget</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>brenda</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word     organization    year\n",
       "0   fiscal  Guilford County  FY2013\n",
       "1     year  Guilford County  FY2013\n",
       "2  adopted  Guilford County  FY2013\n",
       "3   budget  Guilford County  FY2013\n",
       "4   brenda  Guilford County  FY2013"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename col 0\n",
    "df.columns = ['word','organization','year']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.word\n",
    "# Join the elements and sperate them by a single space\n",
    "corpus = ' '.join(word for word in corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fiscal year adopted budget brenda jones county manager sharisse fuller assistant county managerhuman resources director prepared office budget management evaluation michael halford budget director'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the current directory to read the data\n",
    "os.chdir(r\"C:\\Users\\Sultan\\Desktop\\data\\PreprocessedData\\TextFiles\") \n",
    "\n",
    "# Creating a text file\n",
    "text_data = open(\"CombinedData.txt\",\"a\") \n",
    "\n",
    "# Writing the string to the file\n",
    "text_data.write(corpus)\n",
    "\n",
    "# Closing the file\n",
    "text_data.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_filename = \"CombinedData.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'CombinedData.txt'...\n",
      "Corpus is now 133965480 characters long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = u\"\"\n",
    "print(\"Reading '{0}'...\".format(bgt_filename))\n",
    "with codecs.open(bgt_filename, \"r\", \"utf-8\") as book_file:\n",
    "    corpus_raw += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the corpus into sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus contains 15,922,096 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality of the resulting word vectors.\n",
    "num_features = 300\n",
    "\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 3\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-05 16:31:45,407 : INFO : collecting all words and their counts\n",
      "2019-12-05 16:31:45,423 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-12-05 16:31:52,184 : INFO : collected 34079 word types from a corpus of 15922096 raw words and 1 sentences\n",
      "2019-12-05 16:31:52,186 : INFO : Loading a fresh vocabulary\n",
      "2019-12-05 16:31:53,706 : INFO : effective_min_count=3 retains 34079 unique words (100% of original 34079, drops 0)\n",
      "2019-12-05 16:31:53,706 : INFO : effective_min_count=3 leaves 15922096 word corpus (100% of original 15922096, drops 0)\n",
      "2019-12-05 16:31:54,076 : INFO : deleting the raw counts dictionary of 34079 items\n",
      "2019-12-05 16:31:54,076 : INFO : sample=0.001 downsamples 42 most-common words\n",
      "2019-12-05 16:31:54,076 : INFO : downsampling leaves estimated 14607448 word corpus (91.7% of prior 15922096)\n",
      "2019-12-05 16:31:54,361 : INFO : estimated required memory for 34079 words and 300 dimensions: 98829100 bytes\n",
      "2019-12-05 16:31:54,361 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "bgt2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 34079\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(bgt2vec.wv.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-05 16:31:56,050 : INFO : training model with 3 workers on 34079 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=7\n",
      "2019-12-05 16:31:56,174 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:31:56,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:31:56,783 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:31:56,798 : INFO : EPOCH - 1 : training on 15922096 raw words (10000 effective words) took 0.7s, 14071 effective words/s\n",
      "2019-12-05 16:31:56,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:31:56,833 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:31:57,336 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:31:57,338 : INFO : EPOCH - 2 : training on 15922096 raw words (10000 effective words) took 0.5s, 19150 effective words/s\n",
      "2019-12-05 16:31:57,364 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:31:57,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:31:57,884 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:31:57,884 : INFO : EPOCH - 3 : training on 15922096 raw words (10000 effective words) took 0.5s, 18365 effective words/s\n",
      "2019-12-05 16:31:57,920 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:31:57,939 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:31:58,416 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:31:58,416 : INFO : EPOCH - 4 : training on 15922096 raw words (10000 effective words) took 0.5s, 19065 effective words/s\n",
      "2019-12-05 16:31:58,446 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:31:58,454 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:31:58,941 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:31:58,941 : INFO : EPOCH - 5 : training on 15922096 raw words (10000 effective words) took 0.5s, 19742 effective words/s\n",
      "2019-12-05 16:31:58,970 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:31:58,976 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:31:59,442 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:31:59,458 : INFO : EPOCH - 6 : training on 15922096 raw words (10000 effective words) took 0.5s, 20112 effective words/s\n",
      "2019-12-05 16:31:59,477 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:31:59,486 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:31:59,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:31:59,959 : INFO : EPOCH - 7 : training on 15922096 raw words (10000 effective words) took 0.5s, 20305 effective words/s\n",
      "2019-12-05 16:31:59,977 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:31:59,989 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:00,460 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:00,460 : INFO : EPOCH - 8 : training on 15922096 raw words (10000 effective words) took 0.5s, 20057 effective words/s\n",
      "2019-12-05 16:32:00,486 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:00,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:00,993 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:00,993 : INFO : EPOCH - 9 : training on 15922096 raw words (10000 effective words) took 0.5s, 19342 effective words/s\n",
      "2019-12-05 16:32:01,013 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:01,024 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:01,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:01,510 : INFO : EPOCH - 10 : training on 15922096 raw words (10000 effective words) took 0.5s, 19712 effective words/s\n",
      "2019-12-05 16:32:01,533 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:01,542 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:02,026 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:02,026 : INFO : EPOCH - 11 : training on 15922096 raw words (10000 effective words) took 0.5s, 19448 effective words/s\n",
      "2019-12-05 16:32:02,058 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:02,065 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:02,564 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:02,564 : INFO : EPOCH - 12 : training on 15922096 raw words (10000 effective words) took 0.5s, 19325 effective words/s\n",
      "2019-12-05 16:32:02,585 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:02,591 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:03,113 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:03,113 : INFO : EPOCH - 13 : training on 15922096 raw words (10000 effective words) took 0.5s, 18574 effective words/s\n",
      "2019-12-05 16:32:03,136 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:03,143 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:03,614 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:03,614 : INFO : EPOCH - 14 : training on 15922096 raw words (10000 effective words) took 0.5s, 19959 effective words/s\n",
      "2019-12-05 16:32:03,646 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:03,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:04,130 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:04,130 : INFO : EPOCH - 15 : training on 15922096 raw words (10000 effective words) took 0.5s, 19937 effective words/s\n",
      "2019-12-05 16:32:04,156 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:04,163 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:04,631 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:04,631 : INFO : EPOCH - 16 : training on 15922096 raw words (10000 effective words) took 0.5s, 20117 effective words/s\n",
      "2019-12-05 16:32:04,678 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:04,686 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:05,157 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:05,173 : INFO : EPOCH - 17 : training on 15922096 raw words (10000 effective words) took 0.5s, 19231 effective words/s\n",
      "2019-12-05 16:32:05,197 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:05,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:05,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:05,727 : INFO : EPOCH - 18 : training on 15922096 raw words (10000 effective words) took 0.5s, 18321 effective words/s\n",
      "2019-12-05 16:32:05,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:05,756 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:06,244 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:06,244 : INFO : EPOCH - 19 : training on 15922096 raw words (10000 effective words) took 0.5s, 19347 effective words/s\n",
      "2019-12-05 16:32:06,294 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:06,306 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:06,845 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:06,845 : INFO : EPOCH - 20 : training on 15922096 raw words (10000 effective words) took 0.6s, 17447 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-05 16:32:06,877 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:06,884 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:07,354 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:07,356 : INFO : EPOCH - 21 : training on 15922096 raw words (10000 effective words) took 0.5s, 20477 effective words/s\n",
      "2019-12-05 16:32:07,400 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:07,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:07,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:07,877 : INFO : EPOCH - 22 : training on 15922096 raw words (10000 effective words) took 0.5s, 20280 effective words/s\n",
      "2019-12-05 16:32:07,903 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:07,912 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:08,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:08,394 : INFO : EPOCH - 23 : training on 15922096 raw words (10000 effective words) took 0.5s, 19850 effective words/s\n",
      "2019-12-05 16:32:08,418 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:08,426 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:08,880 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:08,880 : INFO : EPOCH - 24 : training on 15922096 raw words (10000 effective words) took 0.5s, 20597 effective words/s\n",
      "2019-12-05 16:32:08,912 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:08,922 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:09,381 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:09,397 : INFO : EPOCH - 25 : training on 15922096 raw words (10000 effective words) took 0.5s, 20174 effective words/s\n",
      "2019-12-05 16:32:09,420 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:09,426 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:09,904 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:09,904 : INFO : EPOCH - 26 : training on 15922096 raw words (10000 effective words) took 0.5s, 19836 effective words/s\n",
      "2019-12-05 16:32:09,937 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:09,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:10,406 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:10,406 : INFO : EPOCH - 27 : training on 15922096 raw words (10000 effective words) took 0.5s, 20212 effective words/s\n",
      "2019-12-05 16:32:10,439 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:10,450 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:10,890 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:10,893 : INFO : EPOCH - 28 : training on 15922096 raw words (10000 effective words) took 0.5s, 21514 effective words/s\n",
      "2019-12-05 16:32:10,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:10,916 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:11,340 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:11,340 : INFO : EPOCH - 29 : training on 15922096 raw words (10000 effective words) took 0.4s, 22374 effective words/s\n",
      "2019-12-05 16:32:11,370 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:11,377 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:11,788 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:11,810 : INFO : EPOCH - 30 : training on 15922096 raw words (10000 effective words) took 0.5s, 22220 effective words/s\n",
      "2019-12-05 16:32:11,836 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:11,852 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:12,329 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:12,331 : INFO : EPOCH - 31 : training on 15922096 raw words (10000 effective words) took 0.5s, 19531 effective words/s\n",
      "2019-12-05 16:32:12,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:12,359 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:12,828 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:12,828 : INFO : EPOCH - 32 : training on 15922096 raw words (10000 effective words) took 0.5s, 20003 effective words/s\n",
      "2019-12-05 16:32:12,859 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:12,865 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:13,345 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:13,345 : INFO : EPOCH - 33 : training on 15922096 raw words (10000 effective words) took 0.5s, 20021 effective words/s\n",
      "2019-12-05 16:32:13,367 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:13,370 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:13,861 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:13,877 : INFO : EPOCH - 34 : training on 15922096 raw words (10000 effective words) took 0.5s, 19203 effective words/s\n",
      "2019-12-05 16:32:13,912 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:13,923 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:14,416 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:14,432 : INFO : EPOCH - 35 : training on 15922096 raw words (10000 effective words) took 0.5s, 18665 effective words/s\n",
      "2019-12-05 16:32:14,449 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:14,453 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:14,896 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:14,896 : INFO : EPOCH - 36 : training on 15922096 raw words (10000 effective words) took 0.5s, 21405 effective words/s\n",
      "2019-12-05 16:32:14,944 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:14,957 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:15,435 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:15,435 : INFO : EPOCH - 37 : training on 15922096 raw words (10000 effective words) took 0.5s, 19234 effective words/s\n",
      "2019-12-05 16:32:15,465 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:15,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:15,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:15,898 : INFO : EPOCH - 38 : training on 15922096 raw words (10000 effective words) took 0.4s, 22392 effective words/s\n",
      "2019-12-05 16:32:15,921 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:15,928 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:16,337 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:16,337 : INFO : EPOCH - 39 : training on 15922096 raw words (10000 effective words) took 0.4s, 23309 effective words/s\n",
      "2019-12-05 16:32:16,364 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:16,369 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:16,769 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:16,769 : INFO : EPOCH - 40 : training on 15922096 raw words (10000 effective words) took 0.4s, 23220 effective words/s\n",
      "2019-12-05 16:32:16,808 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-05 16:32:16,812 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:17,232 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:17,234 : INFO : EPOCH - 41 : training on 15922096 raw words (10000 effective words) took 0.4s, 22721 effective words/s\n",
      "2019-12-05 16:32:17,250 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:17,258 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:17,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:17,687 : INFO : EPOCH - 42 : training on 15922096 raw words (10000 effective words) took 0.4s, 22443 effective words/s\n",
      "2019-12-05 16:32:17,706 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:17,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:18,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:18,125 : INFO : EPOCH - 43 : training on 15922096 raw words (10000 effective words) took 0.4s, 22635 effective words/s\n",
      "2019-12-05 16:32:18,159 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:18,164 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:18,589 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:18,589 : INFO : EPOCH - 44 : training on 15922096 raw words (10000 effective words) took 0.4s, 22569 effective words/s\n",
      "2019-12-05 16:32:18,617 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:18,625 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:19,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:19,044 : INFO : EPOCH - 45 : training on 15922096 raw words (10000 effective words) took 0.4s, 22568 effective words/s\n",
      "2019-12-05 16:32:19,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:19,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:19,492 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:19,492 : INFO : EPOCH - 46 : training on 15922096 raw words (10000 effective words) took 0.4s, 22703 effective words/s\n",
      "2019-12-05 16:32:19,515 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:19,527 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:19,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:19,946 : INFO : EPOCH - 47 : training on 15922096 raw words (10000 effective words) took 0.4s, 22308 effective words/s\n",
      "2019-12-05 16:32:19,973 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:19,987 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:20,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:20,410 : INFO : EPOCH - 48 : training on 15922096 raw words (10000 effective words) took 0.4s, 22322 effective words/s\n",
      "2019-12-05 16:32:20,430 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:20,434 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:20,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:20,848 : INFO : EPOCH - 49 : training on 15922096 raw words (10000 effective words) took 0.4s, 22858 effective words/s\n",
      "2019-12-05 16:32:20,879 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-05 16:32:20,890 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-05 16:32:21,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-05 16:32:21,296 : INFO : EPOCH - 50 : training on 15922096 raw words (10000 effective words) took 0.4s, 22947 effective words/s\n",
      "2019-12-05 16:32:21,296 : INFO : training on a 796104800 raw words (500000 effective words) took 25.3s, 19798 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500000, 796104800)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgt2vec.train(sentences, total_examples=bgt2vec.corpus_count, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save to file, can be useful later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-05 16:32:21,478 : INFO : saving Word2Vec object under trained\\bgt2vec.w2v, separately None\n",
      "2019-12-05 16:32:21,484 : INFO : not storing attribute vectors_norm\n",
      "2019-12-05 16:32:21,488 : INFO : not storing attribute cum_table\n",
      "2019-12-05 16:32:27,553 : INFO : saved trained\\bgt2vec.w2v\n"
     ]
    }
   ],
   "source": [
    "bgt2vec.save(os.path.join(\"trained\", \"bgt2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-05 16:32:27,684 : INFO : loading Word2Vec object from trained\\bgt2vec.w2v\n",
      "2019-12-05 16:32:29,867 : INFO : loading wv recursively from trained\\bgt2vec.w2v.wv.* with mmap=None\n",
      "2019-12-05 16:32:29,867 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-12-05 16:32:29,867 : INFO : loading vocabulary recursively from trained\\bgt2vec.w2v.vocabulary.* with mmap=None\n",
      "2019-12-05 16:32:29,884 : INFO : loading trainables recursively from trained\\bgt2vec.w2v.trainables.* with mmap=None\n",
      "2019-12-05 16:32:29,888 : INFO : setting ignored attribute cum_table to None\n",
      "2019-12-05 16:32:29,957 : INFO : loaded trained\\bgt2vec.w2v\n"
     ]
    }
   ],
   "source": [
    "thrones2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"bgt2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress the word vectors into 2D space and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sultan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_word_vectors_matrix = bgt2vec.wv.syn0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train t-SNE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the big picture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.DataFrame(\n",
    "    [\n",
    "        (word, coords[0], coords[1])\n",
    "        for word, coords in [\n",
    "            (word, all_word_vectors_matrix_2d[bgt2vec.wv.vocab[word].index])\n",
    "            for word in bgt2vec.wv.vocab\n",
    "        ]\n",
    "    ],\n",
    "    columns=[\"word\", \"x\", \"y\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.plot.scatter(\"x\", \"y\", s=10, figsize=(20, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Zoom in to some interesting places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_region(x_bounds, y_bounds):\n",
    "    slice = points[\n",
    "        (x_bounds[0] <= points.x) &\n",
    "        (points.x <= x_bounds[1]) & \n",
    "        (y_bounds[0] <= points.y) &\n",
    "        (points.y <= y_bounds[1])\n",
    "    ]\n",
    "    \n",
    "    ax = slice.plot.scatter(\"x\", \"y\", s=35, figsize=(10, 8))\n",
    "    for i, point in slice.iterrows():\n",
    "        ax.text(point.x + 0.005, point.y + 0.005, point.word, fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**words related endup together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region(x_bounds=(5, 10), y_bounds=(-0.5, -0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore semantic similarities between words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Words closest to the given word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt2vec.most_similar(\"guilford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt2vec.most_similar(\"budget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear relationships between word pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = bgt2vec.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    return start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_similarity_cosmul(\"guilford\",\"budget\",\"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
