{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bgt2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code is generated from © Yuriy Guts, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim.models.word2vec as w2v\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Download NLTK tokenizer models (only the first time)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sultan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the current directory to read the data\n",
    "os.chdir(r\"C:\\Users\\Sultan\\Desktop\\data\\PreprocessedData\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CombinedData.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿word</th>\n",
       "      <th>organization</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fiscal</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>year</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>adopted</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>budget</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>brenda</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ï»¿word     organization    year\n",
       "0   fiscal  Guilford County  FY2013\n",
       "1     year  Guilford County  FY2013\n",
       "2  adopted  Guilford County  FY2013\n",
       "3   budget  Guilford County  FY2013\n",
       "4   brenda  Guilford County  FY2013"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>organization</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fiscal</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>year</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>adopted</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>budget</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>brenda</td>\n",
       "      <td>Guilford County</td>\n",
       "      <td>FY2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word     organization    year\n",
       "0   fiscal  Guilford County  FY2013\n",
       "1     year  Guilford County  FY2013\n",
       "2  adopted  Guilford County  FY2013\n",
       "3   budget  Guilford County  FY2013\n",
       "4   brenda  Guilford County  FY2013"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename col 0\n",
    "df.columns = ['word','organization','year']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.word\n",
    "# Join the elements and sperate them by a single space\n",
    "corpus = ' '.join(word for word in corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fiscal year adopted budget brenda jones county manager sharisse fuller assistant county managerhuman resources director prepared office budget management evaluation michael halford budget director'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the current directory to read the data\n",
    "os.chdir(r\"C:\\Users\\Sultan\\Desktop\\data\\PreprocessedData\\TextFiles\") \n",
    "\n",
    "# Creating a text file\n",
    "text_data = open(\"CombinedData.txt\",\"a\") \n",
    "\n",
    "# Writing the string to the file\n",
    "text_data.write(corpus)\n",
    "\n",
    "# Closing the file\n",
    "text_data.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_filename = \"CombinedData.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'CombinedData.txt'...\n",
      "Corpus is now 107172384 characters long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = u\"\"\n",
    "print(\"Reading '{0}'...\".format(bgt_filename))\n",
    "with codecs.open(bgt_filename, \"r\", \"utf-8\") as book_file:\n",
    "    corpus_raw += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the corpus into sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus contains 12,737,677 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality of the resulting word vectors.\n",
    "num_features = 300\n",
    "\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 3\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-03 11:41:02,344 : INFO : collecting all words and their counts\n",
      "2019-12-03 11:41:02,346 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-12-03 11:41:08,016 : INFO : collected 34079 word types from a corpus of 12737677 raw words and 1 sentences\n",
      "2019-12-03 11:41:08,018 : INFO : Loading a fresh vocabulary\n",
      "2019-12-03 11:41:08,717 : INFO : effective_min_count=3 retains 34079 unique words (100% of original 34079, drops 0)\n",
      "2019-12-03 11:41:08,719 : INFO : effective_min_count=3 leaves 12737677 word corpus (100% of original 12737677, drops 0)\n",
      "2019-12-03 11:41:09,186 : INFO : deleting the raw counts dictionary of 34079 items\n",
      "2019-12-03 11:41:09,190 : INFO : sample=0.001 downsamples 42 most-common words\n",
      "2019-12-03 11:41:09,195 : INFO : downsampling leaves estimated 11685959 word corpus (91.7% of prior 12737677)\n",
      "2019-12-03 11:41:09,535 : INFO : estimated required memory for 34079 words and 300 dimensions: 98829100 bytes\n",
      "2019-12-03 11:41:09,539 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "bgt2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 34079\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(bgt2vec.wv.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-03 11:41:11,644 : INFO : training model with 3 workers on 34079 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=7\n",
      "2019-12-03 11:41:11,921 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:11,925 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:12,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:12,749 : INFO : EPOCH - 1 : training on 12737677 raw words (10000 effective words) took 0.9s, 11644 effective words/s\n",
      "2019-12-03 11:41:12,769 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:12,777 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:13,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:13,387 : INFO : EPOCH - 2 : training on 12737677 raw words (10000 effective words) took 0.6s, 15943 effective words/s\n",
      "2019-12-03 11:41:13,407 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:13,411 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:13,938 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:13,943 : INFO : EPOCH - 3 : training on 12737677 raw words (10000 effective words) took 0.5s, 18361 effective words/s\n",
      "2019-12-03 11:41:13,966 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:13,970 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:14,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:14,566 : INFO : EPOCH - 4 : training on 12737677 raw words (10000 effective words) took 0.6s, 16445 effective words/s\n",
      "2019-12-03 11:41:14,589 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:14,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:15,091 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:15,096 : INFO : EPOCH - 5 : training on 12737677 raw words (10000 effective words) took 0.5s, 19248 effective words/s\n",
      "2019-12-03 11:41:15,120 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:15,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:15,609 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:15,611 : INFO : EPOCH - 6 : training on 12737677 raw words (10000 effective words) took 0.5s, 19783 effective words/s\n",
      "2019-12-03 11:41:15,628 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:15,634 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:16,114 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:16,115 : INFO : EPOCH - 7 : training on 12737677 raw words (10000 effective words) took 0.5s, 20160 effective words/s\n",
      "2019-12-03 11:41:16,135 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:16,143 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:16,741 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:16,745 : INFO : EPOCH - 8 : training on 12737677 raw words (10000 effective words) took 0.6s, 16118 effective words/s\n",
      "2019-12-03 11:41:16,779 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:16,798 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:17,401 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:17,404 : INFO : EPOCH - 9 : training on 12737677 raw words (10000 effective words) took 0.6s, 15529 effective words/s\n",
      "2019-12-03 11:41:17,424 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:17,429 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:17,945 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:17,945 : INFO : EPOCH - 10 : training on 12737677 raw words (10000 effective words) took 0.5s, 18759 effective words/s\n",
      "2019-12-03 11:41:17,965 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:17,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:18,568 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:18,570 : INFO : EPOCH - 11 : training on 12737677 raw words (10000 effective words) took 0.6s, 16264 effective words/s\n",
      "2019-12-03 11:41:18,590 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:18,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:19,087 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:19,089 : INFO : EPOCH - 12 : training on 12737677 raw words (10000 effective words) took 0.5s, 19687 effective words/s\n",
      "2019-12-03 11:41:19,103 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:19,108 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:19,571 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:19,574 : INFO : EPOCH - 13 : training on 12737677 raw words (10000 effective words) took 0.5s, 20960 effective words/s\n",
      "2019-12-03 11:41:19,590 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:19,596 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:20,174 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:20,177 : INFO : EPOCH - 14 : training on 12737677 raw words (10000 effective words) took 0.6s, 17010 effective words/s\n",
      "2019-12-03 11:41:20,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:20,196 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:20,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:20,765 : INFO : EPOCH - 15 : training on 12737677 raw words (10000 effective words) took 0.6s, 17212 effective words/s\n",
      "2019-12-03 11:41:20,781 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:20,787 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:21,238 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:21,240 : INFO : EPOCH - 16 : training on 12737677 raw words (10000 effective words) took 0.5s, 21376 effective words/s\n",
      "2019-12-03 11:41:21,261 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:21,269 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:21,812 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:21,815 : INFO : EPOCH - 17 : training on 12737677 raw words (10000 effective words) took 0.6s, 17749 effective words/s\n",
      "2019-12-03 11:41:21,832 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:21,837 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:22,347 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:22,350 : INFO : EPOCH - 18 : training on 12737677 raw words (10000 effective words) took 0.5s, 18982 effective words/s\n",
      "2019-12-03 11:41:22,370 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:22,373 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:22,861 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:22,863 : INFO : EPOCH - 19 : training on 12737677 raw words (10000 effective words) took 0.5s, 19881 effective words/s\n",
      "2019-12-03 11:41:22,888 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:22,890 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:23,343 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:23,346 : INFO : EPOCH - 20 : training on 12737677 raw words (10000 effective words) took 0.5s, 21409 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-03 11:41:23,362 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:23,365 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:23,830 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:23,832 : INFO : EPOCH - 21 : training on 12737677 raw words (10000 effective words) took 0.5s, 20941 effective words/s\n",
      "2019-12-03 11:41:23,846 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:23,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:24,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:24,298 : INFO : EPOCH - 22 : training on 12737677 raw words (10000 effective words) took 0.5s, 21832 effective words/s\n",
      "2019-12-03 11:41:24,314 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:24,317 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:24,767 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:24,769 : INFO : EPOCH - 23 : training on 12737677 raw words (10000 effective words) took 0.5s, 21630 effective words/s\n",
      "2019-12-03 11:41:24,785 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:24,788 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:25,226 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:25,229 : INFO : EPOCH - 24 : training on 12737677 raw words (10000 effective words) took 0.5s, 22030 effective words/s\n",
      "2019-12-03 11:41:25,243 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:25,250 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:25,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:25,716 : INFO : EPOCH - 25 : training on 12737677 raw words (10000 effective words) took 0.5s, 20899 effective words/s\n",
      "2019-12-03 11:41:25,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:25,734 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:26,201 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:26,203 : INFO : EPOCH - 26 : training on 12737677 raw words (10000 effective words) took 0.5s, 20793 effective words/s\n",
      "2019-12-03 11:41:26,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:26,222 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:26,675 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:26,678 : INFO : EPOCH - 27 : training on 12737677 raw words (10000 effective words) took 0.5s, 21636 effective words/s\n",
      "2019-12-03 11:41:26,695 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:26,701 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:27,170 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:27,172 : INFO : EPOCH - 28 : training on 12737677 raw words (10000 effective words) took 0.5s, 20556 effective words/s\n",
      "2019-12-03 11:41:27,194 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:27,196 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:27,640 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:27,642 : INFO : EPOCH - 29 : training on 12737677 raw words (10000 effective words) took 0.5s, 21889 effective words/s\n",
      "2019-12-03 11:41:27,658 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:27,664 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:28,094 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:28,096 : INFO : EPOCH - 30 : training on 12737677 raw words (10000 effective words) took 0.4s, 22463 effective words/s\n",
      "2019-12-03 11:41:28,108 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:28,114 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:28,544 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:28,546 : INFO : EPOCH - 31 : training on 12737677 raw words (10000 effective words) took 0.4s, 22524 effective words/s\n",
      "2019-12-03 11:41:28,558 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:28,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:29,005 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:29,007 : INFO : EPOCH - 32 : training on 12737677 raw words (10000 effective words) took 0.5s, 22040 effective words/s\n",
      "2019-12-03 11:41:29,020 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:29,026 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:29,479 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:29,481 : INFO : EPOCH - 33 : training on 12737677 raw words (10000 effective words) took 0.5s, 21440 effective words/s\n",
      "2019-12-03 11:41:29,499 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:29,502 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:29,953 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:29,955 : INFO : EPOCH - 34 : training on 12737677 raw words (10000 effective words) took 0.5s, 21429 effective words/s\n",
      "2019-12-03 11:41:29,968 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:29,972 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:30,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:30,714 : INFO : EPOCH - 35 : training on 12737677 raw words (10000 effective words) took 0.8s, 13075 effective words/s\n",
      "2019-12-03 11:41:30,730 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:30,745 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:31,194 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:31,196 : INFO : EPOCH - 36 : training on 12737677 raw words (10000 effective words) took 0.5s, 21689 effective words/s\n",
      "2019-12-03 11:41:31,212 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:31,214 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:31,660 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:31,662 : INFO : EPOCH - 37 : training on 12737677 raw words (10000 effective words) took 0.5s, 21792 effective words/s\n",
      "2019-12-03 11:41:31,676 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:31,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:32,144 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:32,147 : INFO : EPOCH - 38 : training on 12737677 raw words (10000 effective words) took 0.5s, 20917 effective words/s\n",
      "2019-12-03 11:41:32,177 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:32,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:32,619 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:32,622 : INFO : EPOCH - 39 : training on 12737677 raw words (10000 effective words) took 0.5s, 21496 effective words/s\n",
      "2019-12-03 11:41:32,635 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:32,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:33,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:33,075 : INFO : EPOCH - 40 : training on 12737677 raw words (10000 effective words) took 0.4s, 22421 effective words/s\n",
      "2019-12-03 11:41:33,092 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-03 11:41:33,094 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:33,533 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:33,536 : INFO : EPOCH - 41 : training on 12737677 raw words (10000 effective words) took 0.5s, 22151 effective words/s\n",
      "2019-12-03 11:41:33,573 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:33,581 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:34,029 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:34,032 : INFO : EPOCH - 42 : training on 12737677 raw words (10000 effective words) took 0.5s, 21530 effective words/s\n",
      "2019-12-03 11:41:34,045 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:34,054 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:34,496 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:34,499 : INFO : EPOCH - 43 : training on 12737677 raw words (10000 effective words) took 0.5s, 21741 effective words/s\n",
      "2019-12-03 11:41:34,518 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:34,520 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:34,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:34,973 : INFO : EPOCH - 44 : training on 12737677 raw words (10000 effective words) took 0.5s, 21545 effective words/s\n",
      "2019-12-03 11:41:34,990 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:34,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:35,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:35,434 : INFO : EPOCH - 45 : training on 12737677 raw words (10000 effective words) took 0.5s, 22036 effective words/s\n",
      "2019-12-03 11:41:35,450 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:35,454 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:35,922 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:35,924 : INFO : EPOCH - 46 : training on 12737677 raw words (10000 effective words) took 0.5s, 20771 effective words/s\n",
      "2019-12-03 11:41:35,939 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:35,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:36,374 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:36,376 : INFO : EPOCH - 47 : training on 12737677 raw words (10000 effective words) took 0.4s, 22487 effective words/s\n",
      "2019-12-03 11:41:36,389 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:36,399 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:36,880 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:36,883 : INFO : EPOCH - 48 : training on 12737677 raw words (10000 effective words) took 0.5s, 20022 effective words/s\n",
      "2019-12-03 11:41:36,898 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:36,900 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:37,340 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:37,343 : INFO : EPOCH - 49 : training on 12737677 raw words (10000 effective words) took 0.5s, 22091 effective words/s\n",
      "2019-12-03 11:41:37,355 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-03 11:41:37,360 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-03 11:41:37,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-03 11:41:37,792 : INFO : EPOCH - 50 : training on 12737677 raw words (10000 effective words) took 0.4s, 22618 effective words/s\n",
      "2019-12-03 11:41:37,794 : INFO : training on a 636883850 raw words (500000 effective words) took 26.1s, 19123 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500000, 636883850)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgt2vec.train(sentences, total_examples=bgt2vec.corpus_count, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save to file, can be useful later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-03 11:45:12,507 : INFO : saving Word2Vec object under trained\\bgt2vec.w2v, separately None\n",
      "2019-12-03 11:45:12,511 : INFO : not storing attribute vectors_norm\n",
      "2019-12-03 11:45:12,511 : INFO : not storing attribute cum_table\n",
      "2019-12-03 11:45:15,029 : INFO : saved trained\\bgt2vec.w2v\n"
     ]
    }
   ],
   "source": [
    "bgt2vec.save(os.path.join(\"trained\", \"bgt2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-03 11:45:22,254 : INFO : loading Word2Vec object from trained\\bgt2vec.w2v\n",
      "2019-12-03 11:45:24,748 : INFO : loading wv recursively from trained\\bgt2vec.w2v.wv.* with mmap=None\n",
      "2019-12-03 11:45:24,748 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-12-03 11:45:24,756 : INFO : loading vocabulary recursively from trained\\bgt2vec.w2v.vocabulary.* with mmap=None\n",
      "2019-12-03 11:45:24,760 : INFO : loading trainables recursively from trained\\bgt2vec.w2v.trainables.* with mmap=None\n",
      "2019-12-03 11:45:24,764 : INFO : setting ignored attribute cum_table to None\n",
      "2019-12-03 11:45:24,768 : INFO : loaded trained\\bgt2vec.w2v\n"
     ]
    }
   ],
   "source": [
    "thrones2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"bgt2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress the word vectors into 2D space and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sultan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_word_vectors_matrix = bgt2vec.wv.syn0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train t-SNE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the big picture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.DataFrame(\n",
    "    [\n",
    "        (word, coords[0], coords[1])\n",
    "        for word, coords in [\n",
    "            (word, all_word_vectors_matrix_2d[bgt2vec.wv.vocab[word].index])\n",
    "            for word in bgt2vec.wv.vocab\n",
    "        ]\n",
    "    ],\n",
    "    columns=[\"word\", \"x\", \"y\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.plot.scatter(\"x\", \"y\", s=10, figsize=(20, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Zoom in to some interesting places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_region(x_bounds, y_bounds):\n",
    "    slice = points[\n",
    "        (x_bounds[0] <= points.x) &\n",
    "        (points.x <= x_bounds[1]) & \n",
    "        (y_bounds[0] <= points.y) &\n",
    "        (points.y <= y_bounds[1])\n",
    "    ]\n",
    "    \n",
    "    ax = slice.plot.scatter(\"x\", \"y\", s=35, figsize=(10, 8))\n",
    "    for i, point in slice.iterrows():\n",
    "        ax.text(point.x + 0.005, point.y + 0.005, point.word, fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**words related endup together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region(x_bounds=(5, 10), y_bounds=(-0.5, -0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore semantic similarities between words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Words closest to the given word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt2vec.most_similar(\"guilford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt2vec.most_similar(\"budget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear relationships between word pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = bgt2vec.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    return start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_similarity_cosmul(\"guilford\",\"budget\",\"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
