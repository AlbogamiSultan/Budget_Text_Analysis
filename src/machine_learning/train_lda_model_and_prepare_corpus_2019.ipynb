{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>word</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447</td>\n",
       "      <td>Fire</td>\n",
       "      <td>46</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>Fire</td>\n",
       "      <td>44</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>Fire</td>\n",
       "      <td>36</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>444</td>\n",
       "      <td>Fire</td>\n",
       "      <td>31</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>389</td>\n",
       "      <td>County</td>\n",
       "      <td>30</td>\n",
       "      <td>Trust</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number    word  sent_count sentiment category\n",
       "0          447    Fire          46      Fear  Emotion\n",
       "1          302    Fire          44      Fear  Emotion\n",
       "2          303    Fire          36      Fear  Emotion\n",
       "3          444    Fire          31      Fear  Emotion\n",
       "4          389  County          30     Trust  Emotion"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC_df = pd.read_csv(r\"../util/data/FY2019/structured/emotion/GuilfordCountyEmotionDataFY19.csv\")\n",
    "GC_df.drop(['Unnamed: 0'], axis=1,inplace=True)\n",
    "GC_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m spacy download en\n",
    "import re, numpy as np, pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fire']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent)  \n",
    "\n",
    "# Convert to list\n",
    "data = GC_df.word.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])\n",
    "# [['from', 'irwin', 'arnstein', 'subject', 're', 'recommendation', 'on', 'duc', 'summary', 'whats', 'it', 'worth', 'distribution', 'usa', 'expires', 'sat', 'may', 'gmt', ...trucated...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# !python3 -m spacy download en  # run in terminal once\n",
    "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.185*\"grant\" + 0.166*\"level\" + 0.106*\"child\" + 0.094*\"balance\" + '\n",
      "  '0.088*\"food\" + 0.057*\"expense\" + 0.053*\"technology\" + 0.051*\"detention\" + '\n",
      "  '0.039*\"demand\" + 0.033*\"long\"'),\n",
      " (1,\n",
      "  '0.320*\"improve\" + 0.305*\"budget\" + 0.102*\"develop\" + 0.051*\"authorize\" + '\n",
      "  '0.036*\"personal\" + 0.030*\"full\" + 0.015*\"recovery\" + 0.012*\"disposal\" + '\n",
      "  '0.011*\"innovation\" + 0.010*\"vision\"'),\n",
      " (2,\n",
      "  '0.369*\"resource\" + 0.216*\"continue\" + 0.128*\"salary\" + 0.051*\"loss\" + '\n",
      "  '0.030*\"expenditure\" + 0.027*\"population\" + 0.027*\"prevention\" + '\n",
      "  '0.022*\"violence\" + 0.010*\"illegal\" + 0.006*\"machine\"'),\n",
      " (3,\n",
      "  '0.202*\"medical\" + 0.145*\"income\" + 0.091*\"present\" + 0.080*\"improvement\" + '\n",
      "  '0.072*\"legal\" + 0.068*\"soil\" + 0.046*\"account\" + 0.040*\"communication\" + '\n",
      "  '0.038*\"approval\" + 0.026*\"stone\"'),\n",
      " (4,\n",
      "  '0.140*\"management\" + 0.126*\"actual\" + 0.125*\"government\" + 0.122*\"change\" + '\n",
      "  '0.083*\"building\" + 0.079*\"risk\" + 0.066*\"time\" + 0.052*\"call\" + '\n",
      "  '0.039*\"operation\" + 0.028*\"serve\"'),\n",
      " (5,\n",
      "  '0.163*\"fee\" + 0.102*\"community\" + 0.101*\"director\" + 0.092*\"law\" + '\n",
      "  '0.078*\"court\" + 0.073*\"enforcement\" + 0.063*\"conservation\" + 0.051*\"youth\" '\n",
      "  '+ 0.041*\"reimbursement\" + 0.028*\"healthy\"'),\n",
      " (6,\n",
      "  '0.310*\"emergency\" + 0.125*\"school\" + 0.098*\"debt\" + 0.092*\"attorney\" + '\n",
      "  '0.083*\"exceed\" + 0.071*\"real\" + 0.035*\"base\" + 0.035*\"bond\" + '\n",
      "  '0.031*\"appropriation\" + 0.012*\"nurse\"'),\n",
      " (7,\n",
      "  '0.093*\"public\" + 0.087*\"include\" + 0.064*\"high\" + 0.039*\"retirement\" + '\n",
      "  '0.034*\"renovation\" + 0.034*\"effective\" + 0.033*\"progress\" + 0.032*\"share\" + '\n",
      "  '0.030*\"efficient\" + 0.027*\"abuse\"'),\n",
      " (8,\n",
      "  '0.252*\"provide\" + 0.152*\"information\" + 0.099*\"cash\" + 0.093*\"pay\" + '\n",
      "  '0.060*\"supply\" + 0.051*\"recreation\" + 0.041*\"relate\" + 0.040*\"fire\" + '\n",
      "  '0.039*\"jail\" + 0.024*\"rescue\"'),\n",
      " (9,\n",
      "  '0.279*\"planning\" + 0.184*\"tax\" + 0.108*\"increase\" + 0.100*\"system\" + '\n",
      "  '0.081*\"maintenance\" + 0.059*\"disaster\" + 0.033*\"interest\" + '\n",
      "  '0.025*\"customer\" + 0.020*\"late\" + 0.016*\"culture\"')]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           passes=10,\n",
    "                                           alpha = 'auto',\n",
    "                                           eta = 'auto',\n",
    "                                           random_state = 1)\n",
    "\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_df.sentiment = GC_df.sentiment.replace({\"Negative\": \"0\",\"Positive\": \"1\",\"Trust\" :\"1\",\"Sadness\":\"0\",\"Anticipation\":\"1\",\"Surprise\":\"1\",\"Fear\":\"0\",\"Joy\":\"1\",\"Anger\":\"0\",\"Disgust\":\"0\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>word</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447</td>\n",
       "      <td>Fire</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>Fire</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>Fire</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>444</td>\n",
       "      <td>Fire</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>389</td>\n",
       "      <td>County</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number    word  sent_count sentiment category\n",
       "0          447    Fire          46         0  Emotion\n",
       "1          302    Fire          44         0  Emotion\n",
       "2          303    Fire          36         0  Emotion\n",
       "3          444    Fire          31         0  Emotion\n",
       "4          389  County          30         1  Emotion"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17148 entries, 0 to 17147\n",
      "Data columns (total 5 columns):\n",
      "page_number    17148 non-null int64\n",
      "word           17148 non-null object\n",
      "sent_count     17148 non-null int64\n",
      "sentiment      17148 non-null int64\n",
      "category       17148 non-null object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 669.9+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GC_df['sentiment'] = pd.to_numeric(GC_df['sentiment'])\n",
    "GC_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>word</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447</td>\n",
       "      <td>Fire</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>Fire</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>Fire</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>444</td>\n",
       "      <td>Fire</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>389</td>\n",
       "      <td>County</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number    word  sent_count  sentiment category\n",
       "0          447    Fire          46          0  Emotion\n",
       "1          302    Fire          44          0  Emotion\n",
       "2          303    Fire          36          0  Emotion\n",
       "3          444    Fire          31          0  Emotion\n",
       "4          389  County          30          1  Emotion"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "for i in range(len(GC_df)):\n",
    "    top_topics = lda_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(10)]\n",
    "    #The features below were added to increase \n",
    "    topic_vec.extend([GC_df.iloc[i].sent_count]) # counts of reviews for restaurant\n",
    "    topic_vec.extend([len(GC_df.iloc[i].word)]) # length review\n",
    "    train_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04846649,\n",
       " 0.042821117,\n",
       " 0.03781131,\n",
       " 0.0386842,\n",
       " 0.055064,\n",
       " 0.050130684,\n",
       " 0.043984495,\n",
       " 0.087888956,\n",
       " 0.54818475,\n",
       " 0.046964042,\n",
       " 36,\n",
       " 4]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(GC_df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "cv_lr_f1, cv_lrsgd_f1, cv_svcsgd_f1,  = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "    # Logisitic Regression\n",
    "    lr = LogisticRegression(\n",
    "        class_weight= 'balanced',\n",
    "        solver='newton-cg',\n",
    "        fit_intercept=True\n",
    "    ).fit(X_train_scale, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val_scale)\n",
    "    cv_lr_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    # Logistic Regression Mini-Batch SGD\n",
    "    sgd = linear_model.SGDClassifier(\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        loss='log',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd.predict(X_val_scale)\n",
    "    cv_lrsgd_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    # SGD Modified Huber\n",
    "    sgd_huber = linear_model.SGDClassifier(\n",
    "        max_iter=100,\n",
    "        tol=1e-3,\n",
    "        alpha=20,\n",
    "        loss='modified_huber',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd_huber.predict(X_val_scale)\n",
    "    cv_svcsgd_f1.append(f1_score(y_val, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Val f1: 0.692 +- 0.006\n",
      "Logisitic Regression SGD Val f1: 0.655 +- 0.098\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Val f1: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
    "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_f1):.3f} +- {np.std(cv_lrsgd_f1):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "for i in range(len(GC_df)):\n",
    "    top_topics = lda_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(10)]\n",
    "    train_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "cv_lr_f1, cv_lrsgd_f1, cv_svcsgd_f1,  = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "    # Logisitic Regression\n",
    "    lr = LogisticRegression(\n",
    "        class_weight= 'balanced',\n",
    "        solver='newton-cg',\n",
    "        fit_intercept=True\n",
    "    ).fit(X_train_scale, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val_scale)\n",
    "    cv_lr_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    # Logistic Regression Mini-Batch SGD\n",
    "    sgd = linear_model.SGDClassifier(\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        loss='log',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd.predict(X_val_scale)\n",
    "    cv_lrsgd_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    # SGD Modified Huber\n",
    "    sgd_huber = linear_model.SGDClassifier(\n",
    "        max_iter=100,\n",
    "        tol=1e-3,\n",
    "        alpha=20,\n",
    "        loss='modified_huber',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd_huber.predict(X_val_scale)\n",
    "    cv_svcsgd_f1.append(f1_score(y_val, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Val f1: 0.799 +- 0.005\n",
      "Logisitic Regression SGD Val f1: 0.552 +- 0.134\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Val f1: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
    "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_f1):.3f} +- {np.std(cv_lrsgd_f1):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Huber Val f1: 0.696 +- 0.348\n"
     ]
    }
   ],
   "source": [
    "print(f'SVM Huber Val f1: {np.mean(cv_svcsgd_f1):.3f} +- {np.std(cv_svcsgd_f1):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "    # Logisitic Regression\n",
    "    lr = LogisticRegression(\n",
    "        class_weight= None,\n",
    "        solver='newton-cg',\n",
    "        fit_intercept=True\n",
    "    ).fit(X_train_scale, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val_scale)\n",
    "    cv_lr_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    # Logistic Regression Mini-Batch SGD\n",
    "    sgd = linear_model.SGDClassifier(\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        loss='log',\n",
    "        class_weight= None\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd.predict(X_val_scale)\n",
    "    cv_lrsgd_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    # SGD Modified Huber\n",
    "    sgd_huber = linear_model.SGDClassifier(\n",
    "            max_iter=100,\n",
    "            tol=1e-3,\n",
    "            alpha=20,\n",
    "            loss='modified_huber',\n",
    "            class_weight= None\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd_huber.predict(X_val_scale)\n",
    "    cv_svcsgd_f1.append(f1_score(y_val, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Val f1: 0.869 +- 0.003\n",
      "Logisitic Regression SGD Val f1: 0.855 +- 0.008\n",
      "SVM Huber Val f1: 0.870 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Val f1: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
    "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_f1):.3f} +- {np.std(cv_lrsgd_f1):.3f}')\n",
    "print(f'SVM Huber Val f1: {np.mean(cv_svcsgd_f1):.3f} +- {np.std(cv_svcsgd_f1):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "    lda_model.save('lda_train.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
